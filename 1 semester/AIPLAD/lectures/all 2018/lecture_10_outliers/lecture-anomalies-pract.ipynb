{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/header.png\"></center>\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Выявление выбросов и аномалий (практика)</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простой детектор аномалий на временных рядах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**z-score detector**\n",
    "\n",
    "Гипермараметр: ширина окна.\n",
    "\n",
    "Вычиление:\n",
    "$$ z(x_t)=\\left|\\frac{x_t−\\bar{x}_t}{s_t}\\right| $$\n",
    "\n",
    "где\n",
    "$$ x_t=(1/w)\\sum_{i=t−w}^{t-1} x_i $$\n",
    "\n",
    "$$ s_t=(1/w)\\sum_{i=t−w}^{t-1} (x_i - \\bar{x}_t)^2 $$\n",
    "\n",
    "Чем выше скор - тем больше шанс того, что наблюдение аномально\n",
    "\n",
    "Имплементируйте скор для ряда `nyc_taxi.tsv`. Когда мера работать не будет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные о диетах в разных странах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_diet = pd.read_csv('data/diet.csv', sep=';').set_index('Countries').iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные по фроду"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся данными из https://www.kaggle.com/dalpozz/creditcardfraud/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time** - the seconds elapsed between each transaction and the first transaction in the dataset. Numeric  \n",
    "**V1** - First principle component Numeric  \n",
    "**V2** - Second principle component Numeric  \n",
    "**V3** - Third principle component Numeric  \n",
    "...  \n",
    "**V28** - Twenty-eighth principle component Numeric  \n",
    "**Amount** - Transaction Amount Numeric   \n",
    "**Class** - The actual classification classes Numeric  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
    "\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML\n",
    "\n",
    "Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, обратим внимание, что у нас есть шкала времение. Из-за этого может возникнуть нюансы, но мы на них пока не будем обращать внимания. Использовать Time в качестве признака, конечно-же не стоит..\n",
    "\n",
    "Так же обратим внимание, что классы у нас очень несбалансированные. Отсюда возникает несколько вопросов:\n",
    "* Какой **метод** использовать?\n",
    "* Как мерить **качество**?\n",
    "\n",
    "Насчет первого - будем использовать специализированные для этого метод - **изолирующий лес**. \n",
    "\n",
    "Насчет второго - одназначного ответа, увы **нет**. Давайте будем измерять несколькими способами и обсудим что в них плохо или хорошо. Кстати, в подобных задачах хочется получать не просто \"вероятность\" фрода, а саму разметку...\n",
    "\n",
    "FYI можете посчитать интересную статью про меры качества в МО и из экономическую целесообразность - http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import auc, roc_curve, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди импортированных метрик вы, возможно, встретили ранее невиданную: коэффициент корреляции Мэтьюса:\n",
    "$$\\text{MCC}=\\frac{TP\\times TN-FP\\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n",
    "\n",
    "По-большому счету - это просто коэффициент корреляции между двумя бинарными векторами. Но различные эмпирические исследования показали, что он хорошо себя проявляет в задачах с сильным дисбалансом классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выделим тестовое множество, как последние 20% данных\n",
    "* Выделим обучающие, тестовые и валидационные матрицы и разметки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изолирующий лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iso = IsolationForest(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мониторинг работы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отберем несколько объектов с обоих классов для мониторинга\n",
    "\n",
    "Разработаем следующий пайплайн:\n",
    "* Будут перебираться 2 параметра - кол-во сэмплов и кол-во деревьев\n",
    "* Для каждой настойки параметра будем записывать *скор* аномальности\n",
    "* Попробуем прикинуть выходят ли скоры на стабильную траекторию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "161px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
